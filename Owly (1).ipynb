{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83a30d1-4b89-4bda-8ba6-5047c0c61a28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from  matplotlib import pyplot as plt\n",
    "import time\n",
    "import datetime\n",
    "import matplotlib.ticker as mtick\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from wordcloud import WordCloud\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53019414-9ef5-43bb-a646-7b7c303cab2f",
   "metadata": {},
   "source": [
    "# License\n",
    "\n",
    "Please feel free to share this document in any medium you so choose. Attribution is nice, but not required. \n",
    "\n",
    "# Intro\n",
    "\n",
    "This document was produced and minted from a collection of metadata off Archive of Our Own on `2023-03-14`. The data is filtered down to only works tagged under the `Persona 5` fandom, and then parsed here. Here are some fun nerds stats on that data set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd04b171-fbba-4948-ac34-d6e07e3133cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mc = MongoClient(\"mongodb://owlzyhoots:owlzyhoots@aceden.xyz:27017/ao3\")\n",
    "db = mc['ao3']\n",
    "works_col = db['works']\n",
    "targets_col = db['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d583ef2-8f61-4f5e-86df-66ba1f396070",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline = [\n",
    "    {\n",
    "        '$match': {\n",
    "            # 'language': 'English',\n",
    "            # 'fandoms': {'$regex': 'Stardew Valley'},\n",
    "            # 'fandoms':\"Stardew Valley (Video Game)\",\n",
    "            # 'meta.updated': {\"$exists\": True},\n",
    "        }\n",
    "    }, \n",
    "    {\n",
    "        '$project': {\n",
    "            'url': 0,\n",
    "            'relationships': 0,\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        '$sample': {\n",
    "            'size': 100_000\n",
    "        }\n",
    "    }\n",
    "]\n",
    "t1 = time.time()\n",
    "works = pd.DataFrame(list(works_col.aggregate(pipeline, allowDiskUse=True)))\n",
    "# works = pd.DataFrame(list(works_col.find()))\n",
    "t2 = time.time()\n",
    "print(f\"Pipeline ran in [{t2-t1:.3f}] seconds, returning [{works.shape[0]:,.0f}] works.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92369872-8d59-43e8-a8b4-1f862a35c0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"This data set contains [{works.words.sum():,}] total words. Thats [{works.words.sum()/1084170:,.1f}x] the total number of words in the Harry Potter Series.\")\n",
    "print(f\"We found an average of [{works.words.sum()/works.nchapters.sum():,.0f}] words per chapter, and [{works.words.sum()/works.shape[0]:,.0f}] words per work.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa9399f-36d7-4dda-99e1-28ced357552f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"These works are generating an average of [{works.hits.sum()/works.words.sum():.3f}] hits per word.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387fd753-5fab-4a70-962f-a37cdafcc619",
   "metadata": {},
   "source": [
    "# The Graphs\n",
    "The following sections are comprised of various histograms. Each chart is shown first with a log scale, and then a linear scale. This helps show the small data as well as the spikes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024aee64-7ce9-4647-b576-1294a7b99c3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "_ = plt.hist(works.words, bins=range(0, 500_000, 5000), log=True)\n",
    "_ = plt.title('Words Histogram')\n",
    "\n",
    "fig = plt.figure()\n",
    "_ = plt.hist(works.words, bins=range(0, 500_000, 5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31df868-c1ac-416e-8f31-0c26d42988d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"About [{works.words[works.words>10].shape[0] / works.words.shape[0]:7.3%}] of works will have more than 10 words.\")\n",
    "print(f\"About [{works.words[works.words>100].shape[0] / works.words.shape[0]:7.3%}] of works will have more than 100 words.\")\n",
    "print(f\"About [{works.words[works.words>1000].shape[0] / works.words.shape[0]:7.3%}] of works will have more than 1K words.\")\n",
    "print(f\"About [{works.words[works.words>10000].shape[0] / works.words.shape[0]:7.3%}] of works will have more than 10K words.\")\n",
    "print(f\"About [{works.words[works.words>100000].shape[0] / works.words.shape[0]:7.3%}] of works will have more than 100K words.\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(f\"The longest 99% of works will have at least [{works.words.quantile(.01):,.0f}] words\")\n",
    "print(f\"The longest 75% of works will have at least [{works.words.quantile(.25):,.0f}] words\")\n",
    "print(f\"The longest 50% of works will have at least [{works.words.quantile(.5):,.0f}] words\")\n",
    "print(f\"The longest 25% of works will have [{works.words.quantile(1-0.25):,.0f}] words\")\n",
    "print(f\"The longest 5% of works will have [{works.words.quantile(1-0.05):,.0f}] words\")\n",
    "print(f\"The longest 1% of works will have [{works.words.quantile(.99):,.0f}] words\")\n",
    "print(f\"The longest 0.1% of works will have [{works.words.quantile(.999):,.0f}] words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229c36ca-b57d-4888-ad79-12394558569f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "_ = plt.hist(works.nchapters, bins=range(1,201), log=True)\n",
    "_ = plt.title('Chapters Histogram')\n",
    "\n",
    "fig = plt.figure()\n",
    "_ = plt.hist(works.nchapters, bins=range(1,201))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52866bdb-7057-45a0-b908-18ac666ca437",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = works.nchapters[works.nchapters>1].shape[0] / works.nchapters.shape[0]\n",
    "print(f\"Only [{x:.1%}] of works have more than one chapter.\")\n",
    "\n",
    "x = works.nchapters[works.nchapters>10].shape[0] / works.nchapters.shape[0]\n",
    "print(f\"Only [{x:.1%}] of works have more than ten chapters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22fbf0a-2f5f-4424-8343-565984df1dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "_ = plt.hist(works.hits, bins=100, log=True)\n",
    "plt.title('Hits Histogram')\n",
    "\n",
    "fig = plt.figure()\n",
    "_ = plt.hist(works.hits, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321191ce-c250-4e60-b639-690437cbf149",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = works.hits[works.hits>1].shape[0] / works.hits.shape[0]\n",
    "print(f\"[{x:7.3%}] of works have more than 1 hit.\")\n",
    "x = works.hits[works.hits>10].shape[0] / works.hits.shape[0]\n",
    "print(f\"[{x:7.3%}] of works have more than 10 hits.\")\n",
    "x = works.hits[works.hits>100].shape[0] / works.hits.shape[0]\n",
    "print(f\"[{x:7.3%}] of works have more than 100 hits.\")\n",
    "x = works.hits[works.hits>1000].shape[0] / works.hits.shape[0]\n",
    "print(f\"[{x:7.3%}] of works have more than 1,000 hits.\")\n",
    "x = works.hits[works.hits>10000].shape[0] / works.hits.shape[0]\n",
    "print(f\"[{x:7.3%}] of works have more than 10,000 hits.\")\n",
    "x = works.hits[works.hits>100000].shape[0] / works.hits.shape[0]\n",
    "print(f\"[{x:7.3%}] of works have more than 100,000 hits.\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(f\"The top 99% of works will get at least [{works.hits.quantile(1-0.99):,.0f}] hits.\")\n",
    "print(f\"The top 50% of works will get at least [{works.hits.quantile(1-0.50):,.0f}] hits.\")\n",
    "print(f\"The top 10% of works will get more than [{works.hits.quantile(1-0.1):,.0f}] hits.\")\n",
    "print(f\"The top 1% of works will get more than [{works.hits.quantile(1-0.01):,.0f}] hits.\")\n",
    "print(f\"The top 0.1% of works will get more than [{works.hits.quantile(1-0.001):,.0f}] hits.\")\n",
    "print(f\"The top 0.01% of works will get more than [{works.hits.quantile(1-0.0001):,.0f}] hits.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be27696-a1a6-42af-a670-a60cfe6a1829",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "_ = plt.hist(works.kudos, bins=100, log=True)\n",
    "plt.title('Kudos Histogram')\n",
    "\n",
    "fig = plt.figure()\n",
    "_ = plt.hist(works.kudos, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7b1bce-8654-4639-94e9-34285f3ed950",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = works.kudos[works.kudos>0].shape[0] / works.kudos.shape[0]\n",
    "print(f\"[{1-x:.1%}] of works will get no kudos.\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(f\"90% of works will get at least [{works.kudos.quantile(1-0.90):,.0f}] kudos.\")\n",
    "print(f\"50% of works will get at least [{works.kudos.quantile(1-0.50):,.0f}] kudos.\")\n",
    "print(f\"10% of works will get more than [{works.kudos.quantile(1-0.1):,.0f}] kudos.\")\n",
    "print(f\"1% of works will get more than [{works.kudos.quantile(1-0.01):,.0f}] kudos.\")\n",
    "print(f\"0.1% of works will get more than [{works.kudos.quantile(1-0.001):,.0f}] kudos.\")\n",
    "print(f\"0.01% of works will get more than [{works.kudos.quantile(1-0.0001):,.0f}] kudos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bbb1df-e7c7-4316-ae22-91aba7faac06",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "_ = plt.hist(works.comments, bins=100, log=True)\n",
    "plt.title('Comments Histogram')\n",
    "\n",
    "fig = plt.figure()\n",
    "_ = plt.hist(works.comments, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b021cf7-8fe6-48e2-af0e-5d0a3e266eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = works.comments[works.comments>0].shape[0] / works.comments.shape[0]\n",
    "print(f\"Only [{x:.1%}] of works will get at least one comment.\")\n",
    "x = works.comments[works.comments>10].shape[0] / works.comments.shape[0]\n",
    "print(f\"Only [{x:.1%}] of works will get more than 10 comments.\")\n",
    "x = works.comments[works.comments>100].shape[0] / works.comments.shape[0]\n",
    "print(f\"Only [{x:.1%}] of works will get more than 100 comments.\")\n",
    "\n",
    "print()\n",
    "\n",
    "# print(f\"The top 90% of works will get at least [{works.comments.quantile(1-0.90):,.0f}] comments.\")\n",
    "print(f\"The top 50% of works will get at least [{works.comments.quantile(1-0.50):,.0f}] comments.\")\n",
    "print(f\"The top 10% of works will get more than [{works.comments.quantile(1-0.1):,.0f}] comments.\")\n",
    "print(f\"The top 1% of works will get more than [{works.comments.quantile(1-0.01):,.0f}] comments.\")\n",
    "print(f\"The top 0.1% of works will get more than [{works.comments.quantile(1-0.001):,.0f}] comments.\")\n",
    "print(f\"The top 0.01% of works will get more than [{works.comments.quantile(1-0.0001):,.0f}] comments.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e48f07-6b87-4902-8d4b-03a6853f8b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = defaultdict(lambda: 0)\n",
    "for cat in works.categories:\n",
    "    for element in cat:\n",
    "        categories[element] += 1\n",
    "fig = plt.figure()\n",
    "_ = plt.pie(categories.values(), labels=categories.keys(), autopct='%.1f')\n",
    "_ = plt.title('Categories Breakdown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482a7b9c-dc41-48c0-a41f-698ce70d6a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = defaultdict(lambda: 0)\n",
    "for cat in works.rating:\n",
    "    categories[cat] += 1\n",
    "fig = plt.figure()\n",
    "_ = plt.pie(categories.values(), labels=categories.keys(), autopct='%.1f')\n",
    "_ = plt.title('Categories Breakdown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0eef2c-9b30-4c12-b6b4-77101ea20e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "_ = plt.hist(works.date_published.dt.year, bins=range(2014,2025+1,1), log=True)\n",
    "plt.title('Works by Year')\n",
    "\n",
    "fig = plt.figure()\n",
    "_ = plt.hist(works.date_published.dt.year, bins=range(2014,2025+1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bc8a1a-7082-4b70-a088-c773a092d1b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for year in range(2014,2025+1):\n",
    "    fig = plt.figure()\n",
    "    _ = plt.hist(works[works.date_published.dt.year == year].date_published.dt.month,bins=range(1,14,1))\n",
    "    _ = plt.title(f'Works Published by Month of Year in {year}')\n",
    "    _ = plt.xticks(\n",
    "        [1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5, 9.5, 10.5, 11.5, 12.5], \n",
    "        [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc24abb-a188-4a6f-90ff-5f3324da949e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure()\n",
    "_ = plt.hist(works.date_published.dt.month,bins=range(1,14,1))\n",
    "_ = plt.title(f'Works Published by Month of Year in 2014-2023')\n",
    "_ = plt.xticks(\n",
    "    [1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5, 9.5, 10.5, 11.5, 12.5], \n",
    "    [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efaab95-7d4a-40dc-b786-b7d1f5539a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "_ = plt.hist(works.date_published.dt.day,bins=31, density=True)\n",
    "_ = plt.title('Works Published by Day of Month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae604b7-ed2a-49e5-9fe0-3ae56586e302",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "_ = plt.hist(works.date_published.dt.weekday, bins=range(0,8), density=True)\n",
    "plt.title('Works Published by Day of Week')\n",
    "_ = plt.xticks([0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5], [\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a506e767-4408-47ca-ba30-bd1e38882e42",
   "metadata": {},
   "source": [
    "# Deeper Dive\n",
    "\n",
    "What happens when we only look at the top 10% of stories by hits?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3b7ef2-086f-40c4-a492-0be78db6018f",
   "metadata": {},
   "outputs": [],
   "source": [
    "works_top_10_percent_hits = works[works.hits > works.hits.quantile(0.9)]\n",
    "print(f\"There are [{works_top_10_percent_hits.shape[0]:,}] works in this range.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0b8163-46e0-4c65-9636-deaf05eac7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "_ = plt.hist(works_top_10_percent_hits.words, bins=range(0,500_000,5000), log=True)\n",
    "plt.title('Words')\n",
    "\n",
    "fig = plt.figure()\n",
    "_ = plt.hist(works_top_10_percent_hits.words, bins=range(0,500_000,5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2a765e-68cf-4333-a5e9-7d295e2ccdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"These works have a median word count of [{works_top_10_percent_hits.words.median():,.0f}], vs the global median of [{works.words.median():,.0f}].\")\n",
    "print(f\"These works have a mean word count of [{works_top_10_percent_hits.words.mean():,.0f}], vs the global mean of [{works.words.mean():,.0f}].\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a46a7a9-03cf-4660-902e-efa08c747834",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "_ = plt.hist(works_top_10_percent_hits.nchapters, bins=100, log=True)\n",
    "plt.title('Chapters')\n",
    "\n",
    "fig = plt.figure()\n",
    "_ = plt.hist(works_top_10_percent_hits.nchapters, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48019763-497f-4215-8e6e-c61def8ad9ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"These works have a median chapter count of [{works_top_10_percent_hits.nchapters.median():,.1f}], vs the global median of [{works.nchapters.median():,.1f}].\")\n",
    "print(f\"These works have a mean chapter count of [{works_top_10_percent_hits.nchapters.mean():,.1f}], vs the global mean of [{works.nchapters.mean():,.1f}].\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed1c703-80d1-42e6-8360-bf39017b0f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(works_top_10_percent_hits.hits, bins=100, log=True)\n",
    "plt.title('Hits')\n",
    "\n",
    "fig = plt.figure()\n",
    "_ = plt.hist(works_top_10_percent_hits.hits, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e170d98b-4ad3-440a-95eb-861de2dedaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(works_top_10_percent_hits.kudos, bins=100, log=True)\n",
    "plt.title('Kudos')\n",
    "\n",
    "fig = plt.figure()\n",
    "_ = plt.hist(works_top_10_percent_hits.kudos, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d75e2a-8545-4d88-862f-09cbb40d13b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_string = \"\"\n",
    "for tag_list in works.tags:\n",
    "    for tag in tag_list:\n",
    "        cloud_string += f\" {tag}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572776ab-8af5-489c-b098-8c1f0c6f6af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud().generate(cloud_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f1d3a5-3079-493e-a508-011c2b63ebc1",
   "metadata": {},
   "source": [
    "This is a worldcloud of all the tags over ALL fics in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b3c2a8-b040-4118-ad6a-ba0b3760218d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(dpi=300)\n",
    "_ = plt.imshow(wordcloud, interpolation='antialiased')\n",
    "_ = plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cc1373-513c-4f13-96a1-2dcd22b04163",
   "metadata": {},
   "source": [
    "The following data is binned by each year. Early years are a bit weird as there are just so few works that some tags stand out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da47c91-de4f-40e2-9d2a-f6ef70e481e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for year in range(2000, 2025):\n",
    "    cloud_string = \"\"\n",
    "    for tag_list in works.tags[works.date_published.dt.year == year]:\n",
    "        for tag in tag_list:\n",
    "            cloud_string += f\" {tag}\"\n",
    "    try:\n",
    "        wordcloud = WordCloud().generate(cloud_string)\n",
    "    except ValueError:\n",
    "        continue\n",
    "    \n",
    "    fig = plt.figure(dpi=300)\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba87b76-8928-45f4-b61a-0e37065f1c15",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
